# 数据导入说明

## 环境依赖

* docker
* docker-compose
* Java 8
* Scala 2.12
* sbt 1.5

## 导入流程

### 部署MongoDB和Redis
从github clone源代码到本地

```sh
git clone https://github.com/FHamster/SparkDBLP.git
```

或者

```sh
git clone git@github.com:FHamster/SparkDBLP.git
```

在SparkDBLP/mongdb/目录下使用docker-compose部署容器

```sh
docker-compose up
```

### 数据导入

在MongoDB进程开启的前提下才可进行后续操作

#### 脚本导入

SparkDBLP/SparkExp/script.sh文件是自动导入脚本，在SparkDBLP/SparkExp目录下运行可以自动导入

相关的输出保存在*.log文件内

```sh
bash script.sh
```

#### 手动导入

1. 从https://dblp.org/xml/下载dblp.xml.gz并解压到SparkDBLP/SparkExp/whole目录下，解压的结果应该是dblp.xml文件

```sh
gunzip -k dblp.xml.gz
```

2. 运行转换脚本SparkDBLP/SparkExp/src/main/scala/script/ConvertXml.scala

（运行该脚本前应确保SparkDBLP/SparkExp/whole/dblp_cvt目录被删除，该目录会在每次运行时产生）

```sh
rm -rf whole/dblp_cvt && sbt "runMain script.ConvertXml">ConvertXml.log
```

3. 运行数据导入脚本SparkDBLP/SparkExp/src/main/scala/script/Import2MongoDB.scala

```sh
sbt "runMain script.Import2MongoDB">Import2MongoDB.log
```

3. 运行标题单词统计脚本SparkDBLP/SparkExp/src/main/scala/script/TitleWordCount.scla

```sh
sbt "runMain script.TitleWordCount">TitleWordCount.log
```

